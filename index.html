<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Towards Cost-model-based Query Execution over Hybrid Linked Data Fragments Interfaces</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Towards Cost-model-based Query Execution over Hybrid Linked Data Fragments Interfaces">
  <meta name="citation_author" content="Amr Azzam" />
  <meta name="citation_author" content="Ruben Taelman" />
  
  <meta name="citation_publication_date" content="2020/03/04" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="towards-cost-model-based-query-execution-over-hybrid-linked-data-fragments-interfaces">Towards Cost-model-based Query Execution over Hybrid Linked Data Fragments Interfaces</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="#" typeof="foaf:Person schema:Person" resource="#">Amr Azzam</a><a href="#wu"><sup>1</sup></a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="http://www.rubensworks.net/" typeof="foaf:Person schema:Person" resource="http://www.rubensworks.net/#me">Ruben Taelman</a><a href="#idlab"><sup>2</sup></a></li>
  </ul>

  <ul id="affiliations">
    <li id="wu"><sup>1</sup>Vienna University of Economics and Business,
          Vienna, Austria,
          aazzam@wu.ac.at</li>
    <li id="idlab"><sup>2</sup>IDLab,
          ELIS,
          Ghent University – imec,
          ruben.taelman@ugent.be</li>
  </ul>

  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <p>The growing number of decentralized Knowledge Graphs over the Web has created an essential need to provide online querying interfaces to evaluate SPARQL queries over the RDF KGs. For enabling live Knowledge graph querying, it is quite common to adopt SPARQL endpoints that suffer from an availability problem. To alleviate the limited availability, several existing approaches followed the Linked Data Fragment framework which distributes the query evaluation between the client and the server. However, the extensive experiments showed that the current approaches have diverse characteristics that could be incorporated to enhance query performance and server availability. In this paper, we propose a double-sided cost model, on the server-side, the cost model decides the set of interfaces that can be exposed based on the current server load. While the client-side cost aims to find an efficient query execution plan based on the available LDF approaches.</p>

    </div>
</section>

</header>

<main>
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Introduction</h2>
      <p>The rapid growth of open and decentralized Knowledge Graphs over the Web has created an immense demand for public Knowledge Graph query services.
However, enabling live queryable Knowledge Graphs on the Web is difficulty due to their <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/doi:10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">low availability</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>
and expensive hosting of SPARQL endpoints due to their expressive query capabilities.
As an alternative, by publishing data dumps and requiring clients to query over them client-side,
this query effort can be pushed to the client, which may not always be desirable either.
Recently, <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/doi:10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Linked Data Fragments (LDF)</a></span> <span class="references">[<a href="#ref-1">1</a>]</span> was introduced as an idea of exploring the range
of potential Web querying interfaces that exist between SPARQL endpoints and data dumps.
LDF aims to investigate the trade-offs of this range of solutions that distribute the load of the query execution between client and server.</p>

      <p>Several approaches have emerged following this LDF framework such as <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/doi:10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Triple Pattern Fragments (TPF)</a></span> <span class="references">[<a href="#ref-1">1</a>]</span> and Bindings-Restricted Triple Pattern Fragments (brTPF) <span class="references">[<a href="#ref-2">2</a>]</span>, SaGe <span class="references">[<a href="#ref-3">3</a>]</span> and smart-KG <span class="references">[<a href="#ref-4">4</a>]</span>, each offering their own trade-off between the server availability and the query performance. For instance, TPF and brTPF increase server availability at the cost of increased network load. While SaGe enhances average query performance at the cost of reduced server performance when multiple complex queries are running on the server simultaneously. Finally, smart-KG ensures a higher server availability at the cost of higher client effort.</p>

      <p>This LDF research has shown that no single optimal approach exists.
Instead, they each have their advantages and disadvantages.
Depending on different factors, different optimal approaches may apply.
As such, there is a need for a hybrid LDF approach that determines one or more optimal query approaches based on different circumstances.</p>

      <p>A preliminary hybrid LDF approach <span class="references">[<a href="#ref-5">5</a>]</span> investigated the diversity of LDF characteristics <span class="references">[<a href="#ref-6">6</a>, <a href="#ref-7">7</a>]</span>
that can influence query execution plans.
<a property="schema:citation http://purl.org/spar/cito/cites" href="https://papers.dice-research.org/2019/ISWC_PhdConsortium_Hashim/ISWC_PhDConsortium_hashim-public.pdf">Another proposal</a> <span class="references">[<a href="#ref-8">8</a>]</span> suggests a server that provides a different query service based on the current server workload.
None of these approaches allow query interfaces to be negotiated between client and server
depending on factors such as the executed query, server effort, and client capabilities.</p>

      <p>In this paper, we propose such a negotiation-based cost-model.
On the one hand, using a server-side cost model,
the server can expose one or more query interfaces based on its current load,
and the query that the client aims to execute.
On the other hand, the client has a cost-based query optimizer that can determine an efficient query plan over the available interfaces.
This combination of server-side and client-side cost model can ensure efficient usage of server and client resources
to aim for the best possible query performance over the available LDF approaches.</p>

    </div>
</section>

  <section id="solution" inlist="" rel="schema:hasPart" resource="#solution">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Hybrid Framework</h2>

      <p>The goal of our proposed framework
is to allow servers to expose different kinds of interfaces
based on the current server load and the used SPARQL queries.
Instead of making the server allow <em>just one interface</em> type per query,
we propose allowing a <em>collection of interfaces</em> to be exposed per query.
This allows the client to select the most desired interface
based on the clients capabilities and circumstances.</p>

      <p>To achieve such a hybrid of server interfaces,
we make use of a server-side cost model for selecting a set of interfaces based on a given query,
and a client-side cost model for determining a query execution plan based on the allowed interfaces.
<a href="#figure-solution">Fig. 1</a> shows an overview of this framework
where client-side query engines start by sending a query <code>q</code> to the server,
and receive an answer that contains a token <code>t</code> and a set of allowed interfaces <code>I</code>.
Based on the returned interfaces,
the client can determine a query plan over these interfaces.
These (sub)queries can then be resolved by requesting the appropriate interfaces using the given token.
Hereafter, we explain the server and client processes in more detail.</p>

      <figure id="figure-solution">
<img src="img/hybrid-querying.svg" alt="[Hybrid Linked Data Fragments]" style="height: 8em" />
<figcaption>
          <p><span class="label">Fig. 1:</span> Overview of client-server communication for a cost-model-based query execution over a hybrid of Linked Data Fragments interfaces.</p>
        </figcaption>
</figure>

      <h3 id="server-component">Server Component</h3>

      <p>The server component of our framework consists of
a cost model for calculating a set of allow interfaces,
and a token-based wrapper over a set of interfaces.
We explain these two elements hereafter.</p>

      <h4 id="cost-model">Cost Model</h4>

      <p>The goal of this server-side cost model is to ensure the server availability,
and to allow queries to be executed as fast as possible.
Since the latter goal can sometimes be detrimental to the server availability,
for example when many concurrent users are sending highly complex queries,
the availability goal must always have priority in the model.</p>

      <p>Based on these goals, the model should be able to make a suggestion for a set of interfaces
based on a given query and a set of internal metrics.
For this, we propose a set of internal metrics such as the current CPU usage, memory usage and network I/O.
The server administrator must be able to configure an upper limit for these metrics,
so that the cost model can select interfaces that optimize both goals.</p>

      <p><a href="#algorithm-get-allowed-interfaces">Listing 1</a> shows the pseudocode of an algorithm
that can be used to calculate a set of allowed interfaces.
In this algorithm, <code>CalculateMetricIncrease</code> would still need a concrete implementation.
For this, different possibilities exist,
such as heuristics to predict query complexity based on the number of triple patterns and query operators.
<!--For each incoming query `q`,
the algorithm iterates over all available interfaces, and all metrics.
For each metric, the expected metric value increase is calculated
for the given query using `CalculateMetricIncrease(q, metric)`.
If when adding this value to the current metric's value does not exceed the maximum allowed metric value,
then the loop continues.
If all metrics pass for a given interface,
then an interface is considered an *allowed interface*.--></p>

      <figure id="algorithm-get-allowed-interfaces" class="listing">
<pre><code>GetInterfaces(q, metrics, interfaces, metricsCurrent, metricsMax)
</code><code>  allowedInterfaces = []
</code><code>  FOREACH interface IN interfaces
</code><code>    validInterface = true
</code><code>    FOREACH metric IN metrics
</code><code>    increase = CalculateMetricIncrease(q, interface)
</code><code>      IF metricsCurrent(metric) + increase &gt; metricsMax(metric)
</code><code>        validInterface = false
</code><code>    IF validInterface
</code><code>      allowedInterfaces.push(validInterface)
</code><code>  RETURN allowedInterfaces</code></pre>
<figcaption>
          <p><span class="label">Listing 1:</span> Algorithm for calculating the allowed interfaces for a given query.</p>
        </figcaption>
</figure>

      <!--Based on our algorithm, the `CalculateMetricIncrease` still needs a concrete implementation.
For this, different possibilities exist.
For instance, heuristics for query complexity can be used to estimate metric value increases,
such as query string length, the depth of the basic graph patterns or the used query operators.
Furthermore, other implementations may be based on query log analysis,
where models could be based on machine learning techniques.-->

      <h4 id="interface-wrapper">Interface Wrapper</h4>

      <p>Based on the server-side cost model,
the server can wrap over a number of LDF interfaces
that the publisher wants to expose.
This wrapper is a proxy that accepts SPARQL queries,
and replies with a token and a set of allowed interfaces
that have been calculated for the given query using the server-side cost model.
The token is <em>required</em> for performing any requests to any of the wrapped LDF interfaces.</p>

      <p>This token should be seen as temporary <em>permission</em>
to make use of a specific set of query capabilities from the data publisher.
It is important that the server validates this token upon every request to an LDF interface.
If the server would not do this,
a client could simply ignore the set of allowed interfaces,
and always execute queries against the most expressive interface (e.g. SPARQL endpoint),
even if this interface was not allowed by the server.</p>

      <!--Optionally, the server could keep track of token usages
to check whether or not the client does indeed use it
to execute the query it got permission for, and nothing more.
Since keeping track of this token usage could require significant server effort,
simpler heuristics could be used,
such as limiting the temporal validity of a token to the estimated execution time.-->

      <!--An optional enhancement of the server could be to directly
reply with a SPARQL query response
if the only allowed server was a SPARQL endpoint,
because the client will be likely to make such a subsequent request.-->

      <h3 id="client-component">Client Component</h3>

      <p>In most cases, the primary goal of clients is to execute queries as fast as possible,
either in overal execution time,
or in continuous efficiency.
There could however be a number of metrics that can soften this need for fast query execution,
such as reducing CPU or bandwidth usage, or optimizing for early results <span class="references">[<a href="#ref-9">9</a>]</span></p>

      <p>Using the server-side hybrid of LDF interfaces that was explained before,
clients will retrieve a set of allowed interfaces based on a given query.
Based on these interfaces, the client should determine a query plan that makes use of the interfaces
in such a way that is as efficient as possible with respect to the client’s metrics.
While most client-side query algorithms focus on splitting up queries for execution against a single type of interface,
additional algorithms are needed for <em>intelligently combining interfaces</em> for certain subqueries <span class="references">[<a href="#ref-5">5</a>]</span>.</p>

      <p>Next to these client metrics, there could be additional parameters that could influence
the selection of interfaces to query from.
For example, if the client knows beforehand that it will have to execute <em>many</em> queries against the same dataset,
then it might be more efficient to download the full dump of the dataset,
even if a SPARQL endpoint was allowed for the initial query.
Another case that can influence interface selection
would be when certain partial dumps of the dataset are already available locally,
or within a network of peers <span class="references">[<a href="#ref-10">10</a>]</span>.</p>

    </div>
</section>

  <section id="conclusions" inlist="" rel="schema:hasPart" resource="#conclusions">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Conclusions</h2>

      <p class="todo">In this paper, we presented an approach that exploits the different characteristics of the currently existing LDF interfaces though using a negotiation-based cost model. On the server-side, the server-cost model will ensure exposing that the LDF interfaces taking into consideration the current server resources. On the client-side, the cost model will establish an efficient query execution plan based on the available server interfaces. We plan to implement our double-side (client/server) cost models on top of Comunica which is a flexible query engine platform which supports multiple heterogeneous interfaces. Comunica introduced Actor-Mediator-Bus Pattern that will allow us to integrate multiple Knowledge Graph  interfaces.</p>

      <p class="todo">plans for evaluation, perspectives</p>

    </div>
</section>

</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="https://dx.doi.org/doi:10.1016/j.websem.2016.03.003" typeof="schema:Article">Verborgh, R., Vander Sande, M., Hartig, O., Van Herwegen, J., De Vocht, L., De Meester, B., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: a Low-cost Knowledge Graph Interface for the Web. Journal of Web Semantics. 37–38, 184–206 (2016).</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-319-48472-3_48" typeof="schema:Article">Hartig, O., Buil-Aranda, C.: Bindings-Restricted Triple Pattern Fragments. In: Proc. of ODBASE. pp. 762–779 (2016).</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="#minier2019sage" typeof="schema:Article">Minier, T., Skaf-Molli, H., Molli, P.: SaGe: Web Preemption for Public SPARQL Query Services. The World Wide Web Conference. 1268–1278 (2019).</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="https://dx.doi.org/10.1145/3366423.338017" typeof="schema:Article">Azzam, A., Fernandez, J., Acosta, M., Beno, M., Polleres, A.: SMART-KG: Hybrid shipping for SPARQL querying on the web. In: Proc. of The Web Conference (2020).</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#hetero" typeof="schema:Article">Montoya, G., Aebeloe, C., Hose, K.: Towards Efficient Query Processing over Heterogeneous RDF Interfaces. Presented at the August (2018).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#Montoya2019AnalysisOT" typeof="schema:Article">Montoya, G., Keles, I., Hose, K.: Analysis of the Effect of Query Shapes on Performance over LDF Interfaces. In: QuWeDa@ISWC (2019).</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-030-00668-6_6" typeof="schema:CreativeWork">Heling, L., Acosta, M., Maleshkova, M., Sure-Vetter, Y.: Querying Large Knowledge Graphs over Triple Pattern Fragments: An Empirical Study: 17th International Semantic Web Conference, Monterey, CA, USA, October 8–12, 2018, Proceedings, Part II. Presented at the January (2018).</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="https://papers.dice-research.org/2019/ISWC_PhdConsortium_Hashim/ISWC_PhDConsortium_hashim-public.pdf" typeof="schema:Article">Khan, H.: Towards More Intelligent SPARQL Querying Interfaces. In: International Semantic Web Conference (2019).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="#diefficiency" typeof="schema:Article">Acosta, M., Vidal, M.-E., Sure-Vetter, Y.: Diefficiency metrics: measuring the continuous efficiency of query processing approaches. In: International Semantic Web Conference. pp. 3–19. Springer (2017).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="#webp2p" typeof="schema:Article">Grall, A., Skaf-Molli, H., Molli, P.: SPARQL query execution in networks of web browsers. Presented at the (2018).</dd>
</dl>
</section>
</footer>



</body>
</html>
